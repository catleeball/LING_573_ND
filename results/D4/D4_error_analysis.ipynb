{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show full text in dataframe display\n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SAND Data\n",
    "Load the test and dev data into different dataframes. (Currently don't have the training data -- I will poke that for count statistics separately.)\n",
    "\n",
    "Includes the true labels, as well as the predicted labels from the two revised models in D4:\n",
    "- SAND-Finetuned RoBERTa\n",
    "- Ensemble Decision Tree, trained on D3 models:\n",
    "    - SARC-Finetuned BERT (no context)\n",
    "    - SARC-Finetuned RoBERTa (no context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Texts and True Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SAND Data from file\n",
    "sand_dev_file = \"../../data/scraped/dev.json\"\n",
    "sand_test_file = \"../../data/scraped/test.json\"\n",
    "\n",
    "with open(sand_dev_file, 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open(sand_test_file, 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SAND Dev DataFrame\n",
    "dev_ids = {\"id\": list(dev_data.keys())}\n",
    "dev_texts_labels = list(dev_data.values())\n",
    "\n",
    "dev_id_df = pd.DataFrame(dev_ids)\n",
    "dev_txt_lbl_df = pd.DataFrame(dev_texts_labels)\n",
    "\n",
    "sand_dev_df = dev_id_df.join(dev_txt_lbl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SAND Test DataFrame\n",
    "test_ids = {\"id\": list(test_data.keys())}\n",
    "test_texts_labels = list(test_data.values())\n",
    "\n",
    "test_id_df = pd.DataFrame(test_ids)\n",
    "test_txt_lbl_df = pd.DataFrame(test_texts_labels)\n",
    "\n",
    "sand_test_df = test_id_df.join(test_txt_lbl_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Predictions:\n",
    "For `sand_dev_df`:\n",
    "- `outputs/D4/adaptation/devtest/d4_ensemble_sarc_d3_model.out`\n",
    "- `outputs/D4/adaptation/devtest/d4_roberta_sand_model.out`\n",
    "\n",
    "For `sand_test_df`:\n",
    "- `outputs/D4/adaptation/evaltest/d4_ensemble_sarc_d3_model.out`\n",
    "- `outputs/D4/adaptation/evaltest/d4_roberta_sand_model.out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ensemble_pred</th>\n",
       "      <th>d4_roberta_pred</th>\n",
       "      <th>d4_roberta_neg</th>\n",
       "      <th>d4_roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cu7n7ur</td>\n",
       "      <td>ADHD is a recognized disability with conditions as listed in this article.  According to this website  gt504 plans are for K12 public school students with disabilities.  And according to their page on IEPs   gtKids from age 3 through high school graduation or a maximum age of 22 whichever comes first may be eligible for an IEP.  Please visit this page on this subs wiki for college assistance. If your college has their own health care system you might be able to get medication from them. I believe that if you are 18 or older according to HIPAA laws your parents do not have the right to your medical information even if their insurance is paying for it  but this may depend upon the state in which you live. This PDF explains a little of it you can do a search in this PDF for 18 to find the relevant sections.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020131</td>\n",
       "      <td>0.979869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  cu7n7ur   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0  ADHD is a recognized disability with conditions as listed in this article.  According to this website  gt504 plans are for K12 public school students with disabilities.  And according to their page on IEPs   gtKids from age 3 through high school graduation or a maximum age of 22 whichever comes first may be eligible for an IEP.  Please visit this page on this subs wiki for college assistance. If your college has their own health care system you might be able to get medication from them. I believe that if you are 18 or older according to HIPAA laws your parents do not have the right to your medical information even if their insurance is paying for it  but this may depend upon the state in which you live. This PDF explains a little of it you can do a search in this PDF for 18 to find the relevant sections.   \n",
       "\n",
       "   label ensemble_pred d4_roberta_pred  d4_roberta_neg  d4_roberta_pos  \n",
       "0      1             0               1        0.020131        0.979869  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add SAND Dev predictions:\n",
    "ensemble_file = '../../outputs/D4/adaptation/devtest/d4_ensemble_sarc_d3_model.out'\n",
    "roberta_file = '../../outputs/D4/adaptation/devtest/d4_roberta_sand_model.out'\n",
    "\n",
    "with open(ensemble_file, 'r') as f:\n",
    "    ensemble_preds = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        ensemble_preds.append(split_line[0].split(\": \")[1])\n",
    "\n",
    "with open(roberta_file, 'r') as f:\n",
    "    roberta_preds = []\n",
    "    prob_neg = []\n",
    "    prob_pos = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        roberta_preds.append(split_line[0].split(\": \")[1])\n",
    "        prob_neg.append(float(split_line[2].split(\": \")[1]))\n",
    "        prob_pos.append(float(split_line[3]))\n",
    "\n",
    "sand_dev_df['ensemble_pred'] = ensemble_preds\n",
    "sand_dev_df['d4_roberta_pred'] = roberta_preds\n",
    "sand_dev_df['d4_roberta_neg'] = prob_neg\n",
    "sand_dev_df['d4_roberta_pos'] = prob_pos\n",
    "sand_dev_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ensemble_pred</th>\n",
       "      <th>d4_roberta_pred</th>\n",
       "      <th>d4_roberta_neg</th>\n",
       "      <th>d4_roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jd7vd2q</td>\n",
       "      <td>Only if its a band I would like to see coming to town and I see something about it after the fact!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967596</td>\n",
       "      <td>0.032405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  jd7vd2q   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "0  Only if its a band I would like to see coming to town and I see something about it after the fact!   \n",
       "\n",
       "   label ensemble_pred d4_roberta_pred  d4_roberta_neg  d4_roberta_pos  \n",
       "0      0             1               0        0.967596        0.032405  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add SAND Test Predictions\n",
    "ensemble_file = '../../outputs/D4/adaptation/evaltest/d4_ensemble_sarc_d3_model.out'\n",
    "roberta_file = '../../outputs/D4/adaptation/evaltest/d4_roberta_sand_model.out'\n",
    "\n",
    "with open(ensemble_file, 'r') as f:\n",
    "    ensemble_preds = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        ensemble_preds.append(split_line[0].split(\": \")[1])\n",
    "\n",
    "with open(roberta_file, 'r') as f:\n",
    "    roberta_preds = []\n",
    "    prob_neg = []\n",
    "    prob_pos = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        roberta_preds.append(split_line[0].split(\": \")[1])\n",
    "        prob_neg.append(float(split_line[2].split(\": \")[1]))\n",
    "        prob_pos.append(float(split_line[3]))\n",
    "\n",
    "sand_test_df['ensemble_pred'] = ensemble_preds\n",
    "sand_test_df['d4_roberta_pred'] = roberta_preds\n",
    "sand_test_df['d4_roberta_neg'] = prob_neg\n",
    "sand_test_df['d4_roberta_pos'] = prob_pos\n",
    "sand_test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SARC Data\n",
    "Load the test and dev data into different dataframes.\n",
    "\n",
    "Includes the true labels, as well as the predicted labels from the two revised models in D4:\n",
    "- SAND-Finetuned RoBERTa\n",
    "- Ensemble Decision Tree, trained on D3 models:\n",
    "    - SARC-Finetuned BERT (no context)\n",
    "    - SARC-Finetuned RoBERTa (no context)\n",
    "\n",
    "NOTE: Because our D4 models don't use context, these columns (posts, post_ids, context_size) will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text and True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc_dev_file = \"../../data/sarc/dev-comments-balanced.json\"\n",
    "sarc_test_file = \"../../data/sarc/test-comments-balanced.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SARC data from file\n",
    "with open(sarc_dev_file, 'r') as f:\n",
    "    sarc_dev_data = json.load(f)\n",
    "sarc_dev_df = pd.DataFrame.from_records(sarc_dev_data)\n",
    "\n",
    "with open(sarc_test_file, 'r') as f:\n",
    "    sarc_test_data = json.load(f)\n",
    "sarc_test_df = pd.DataFrame.from_records(sarc_test_data)\n",
    "\n",
    "# Drop cluttered columns (comment this out if you want SARC context)\n",
    "sarc_dev_df = sarc_dev_df.drop(columns=[\"posts\", \"post_ids\", \"context_size\"])\n",
    "sarc_dev_df = sarc_dev_df.rename(columns={\"response\":\"text\", \"response_id\":\"id\"})\n",
    "\n",
    "sarc_test_df = sarc_test_df.drop(columns=[\"posts\", \"post_ids\", \"context_size\"])\n",
    "sarc_test_df = sarc_test_df.rename(columns={\"response\":\"text\", \"response_id\":\"id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Predictions:\n",
    "For `sarc_dev_df`:\n",
    "- `outputs/D4/primary/devtest/d4_ensemble_sarc_d3_model.out`\n",
    "- `outputs/D4/primary/devtest/d4_roberta_sand_model.out`\n",
    "\n",
    "For `sarc_test_df`:\n",
    "- `outputs/D4/primary/evaltest/d4_ensemble_sarc_d3_model.out`\n",
    "- `outputs/D4/primary/evaltest/d4_roberta_sand_model.out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ensemble_pred</th>\n",
       "      <th>d4_roberta_pred</th>\n",
       "      <th>d4_roberta_neg</th>\n",
       "      <th>d4_roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07fd66</td>\n",
       "      <td>Religion must have the answer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96435</td>\n",
       "      <td>0.03565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           text label ensemble_pred d4_roberta_pred  \\\n",
       "0  c07fd66  Religion must have the answer     1             1               0   \n",
       "\n",
       "   d4_roberta_neg  d4_roberta_pos  \n",
       "0         0.96435         0.03565  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add SAND Dev predictions:\n",
    "ensemble_file = '../../outputs/D4/primary/devtest/d4_ensemble_sarc_d3_model.out'\n",
    "roberta_file = '../../outputs/D4/primary/devtest/d4_roberta_sand_model.out'\n",
    "\n",
    "with open(ensemble_file, 'r') as f:\n",
    "    ensemble_preds = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        ensemble_preds.append(split_line[0].split(\": \")[1])\n",
    "\n",
    "with open(roberta_file, 'r') as f:\n",
    "    roberta_preds = []\n",
    "    prob_neg = []\n",
    "    prob_pos = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        roberta_preds.append(split_line[0].split(\": \")[1])\n",
    "        prob_neg.append(float(split_line[2].split(\": \")[1]))\n",
    "        prob_pos.append(float(split_line[3]))\n",
    "\n",
    "sarc_dev_df['ensemble_pred'] = ensemble_preds\n",
    "sarc_dev_df['d4_roberta_pred'] = roberta_preds\n",
    "sarc_dev_df['d4_roberta_neg'] = prob_neg\n",
    "sarc_dev_df['d4_roberta_pos'] = prob_pos\n",
    "sarc_dev_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ensemble_pred</th>\n",
       "      <th>d4_roberta_pred</th>\n",
       "      <th>d4_roberta_neg</th>\n",
       "      <th>d4_roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07nkao</td>\n",
       "      <td>Yes, cuz tax cuts will help those w/o jobs!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965571</td>\n",
       "      <td>0.034429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         text label ensemble_pred  \\\n",
       "0  c07nkao  Yes, cuz tax cuts will help those w/o jobs!     1             1   \n",
       "\n",
       "  d4_roberta_pred  d4_roberta_neg  d4_roberta_pos  \n",
       "0               0        0.965571        0.034429  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add SAND Dev predictions:\n",
    "ensemble_file = '../../outputs/D4/primary/evaltest/d4_ensemble_sarc_d3_model.out'\n",
    "roberta_file = '../../outputs/D4/primary/evaltest/d4_roberta_sand_model.out'\n",
    "\n",
    "with open(ensemble_file, 'r') as f:\n",
    "    ensemble_preds = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        ensemble_preds.append(split_line[0].split(\": \")[1])\n",
    "\n",
    "with open(roberta_file, 'r') as f:\n",
    "    roberta_preds = []\n",
    "    prob_neg = []\n",
    "    prob_pos = []\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split(\", \")\n",
    "        roberta_preds.append(split_line[0].split(\": \")[1])\n",
    "        prob_neg.append(float(split_line[2].split(\": \")[1]))\n",
    "        prob_pos.append(float(split_line[3]))\n",
    "\n",
    "sarc_test_df['ensemble_pred'] = ensemble_preds\n",
    "sarc_test_df['d4_roberta_pred'] = roberta_preds\n",
    "sarc_test_df['d4_roberta_neg'] = prob_neg\n",
    "sarc_test_df['d4_roberta_pos'] = prob_pos\n",
    "sarc_test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Loaded Dfs:\n",
    "`sand_dev_df` - Adaptation task dev set\n",
    "\n",
    "`sand_test_df` - Adaptation task test set\n",
    "\n",
    "`sarc_dev_df` - Primary task dev set\n",
    "\n",
    "`sarc_test_df` - Primary task test set\n",
    "\n",
    "**Columns**\n",
    "- `id` - The unique ID of the text (\"response_id\" in the original SARC data files)\n",
    "- `text` - The text of the response used as input.\n",
    "- `label` - The true label. 0 if non-sarcastic. 1 if sarcastic.\n",
    "- `ensemble_pred` - The predicted label, as made by the D4 Decision Tree ensemble model.\n",
    "- `d4_roberta_pred` - The predicted label, as made by the D4 SAND-Finetuned RoBERTa model.\n",
    "    - `d4_roberta_neg` - The probability of the prediction \"0\"\n",
    "    - `d4_roberta_pos` - The probability of the prediction \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAND Dev True Label Counts:\n",
      "label\n",
      "0    24881\n",
      "1    23355\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SAND Dev Ensemble Pred Counts:\n",
      "ensemble_pred\n",
      "0    43515\n",
      "1     4721\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SAND Dev RoBERTa Pred Counts:\n",
      "d4_roberta_pred\n",
      "0    27181\n",
      "1    21055\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SAND Dev Label Count Stats:\n",
    "print(\"SAND Dev True Label Counts:\")\n",
    "print(sand_dev_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nSAND Dev Ensemble Pred Counts:\")\n",
    "print(sand_dev_df['ensemble_pred'].value_counts())\n",
    "\n",
    "print(\"\\nSAND Dev RoBERTa Pred Counts:\")\n",
    "print(sand_dev_df['d4_roberta_pred'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAND Test True Label Counts:\n",
      "label\n",
      "0    24721\n",
      "1    23465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SAND Test Ensemble Pred Counts:\n",
      "ensemble_pred\n",
      "0    43487\n",
      "1     4699\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SAND Test RoBERTa Pred Counts:\n",
      "d4_roberta_pred\n",
      "0    27154\n",
      "1    21032\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SAND Test Label Count Stats:\n",
    "print(\"SAND Test True Label Counts:\")\n",
    "print(sand_test_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nSAND Test Ensemble Pred Counts:\")\n",
    "print(sand_test_df['ensemble_pred'].value_counts())\n",
    "\n",
    "print(\"\\nSAND Test RoBERTa Pred Counts:\")\n",
    "print(sand_test_df['d4_roberta_pred'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARC Dev True Label Counts:\n",
      "label\n",
      "1    12854\n",
      "0    12854\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SARC Dev Ensemble Pred Counts:\n",
      "ensemble_pred\n",
      "1    13054\n",
      "0    12654\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SARC Dev RoBERTa Pred Counts:\n",
      "d4_roberta_pred\n",
      "0    25441\n",
      "1      267\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SARC Dev Label Count Stats:\n",
    "print(\"SARC Dev True Label Counts:\")\n",
    "print(sarc_dev_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nSARC Dev Ensemble Pred Counts:\")\n",
    "print(sarc_dev_df['ensemble_pred'].value_counts())\n",
    "\n",
    "print(\"\\nSARC Dev RoBERTa Pred Counts:\")\n",
    "print(sarc_dev_df['d4_roberta_pred'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARC Test True Label Counts:\n",
      "label\n",
      "1    32333\n",
      "0    32333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SARC Test Ensemble Pred Counts:\n",
      "ensemble_pred\n",
      "1    33129\n",
      "0    31537\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SARC Test RoBERTa Pred Counts:\n",
      "d4_roberta_pred\n",
      "0    63896\n",
      "1      770\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SAND Test Label Count Stats:\n",
    "print(\"SARC Test True Label Counts:\")\n",
    "print(sarc_test_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nSARC Test Ensemble Pred Counts:\")\n",
    "print(sarc_test_df['ensemble_pred'].value_counts())\n",
    "\n",
    "print(\"\\nSARC Test RoBERTa Pred Counts:\")\n",
    "print(sarc_test_df['d4_roberta_pred'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "We still need:\n",
    "- Word count statistics (avg, max, min) on the SARC and SAND dataset.\n",
    " - We think SAND probably has longer texts overall, so the important sarcastic responses may be getting cut out of the BERT embeddings.\n",
    "- General statistics on the training data. (I just don't have it at the moment.)\n",
    "    - Total # of data points\n",
    "    - \\# of sarcastic texts\n",
    "    - \\# of non-sarcastic texts\n",
    "    - Word count statistics (avg, max, min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAND vs SARC Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length\n",
    "print('SAND DATA')\n",
    "print('------------------------------')\n",
    "print(sand_dev_df['text'].str.len())\n",
    "print('Average text length (chars):', sand_dev_df['text'].apply(len).mean())\n",
    "print('Min text length:', sand_dev_df['text'].apply(len).min())\n",
    "print('Max text length:', sand_dev_df['text'].apply(len).max())\n",
    "\n",
    "print('SARC DATA')\n",
    "print('------------------------------')\n",
    "print(sarc_dev_df['text'].str.len())\n",
    "print('Average text length (chars):', sarc_dev_df['text'].apply(len).mean())\n",
    "print('Min text length:', sarc_dev_df['text'].apply(len).min())\n",
    "print('Max text length:', sarc_dev_df['text'].apply(len).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "573_ND",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
