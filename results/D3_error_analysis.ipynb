{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas import DataFrame, concat, set_option\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = '../data/sarc/dev-comments/balanced.json'  # DOUBLE CHECK FILE PATH\n",
    "model_out_file = 'd3_baseline.out'  # CHANGE FILE PATH\n",
    "\n",
    "with open(test_data_file, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "with open(model_out_file, 'r') as f:\n",
    "    # save output file in dict\n",
    "    model_out = {'pred':[], 'gold':[], 'prob_negative':[], 'prob_positive':[]}\n",
    "\n",
    "    for line in f:\n",
    "        lst = line.replace(',', '').split()\n",
    "        # index labels and probabilities from each line, store in dict\n",
    "        model_out['pred'].append(lst[1])\n",
    "        model_out['gold'].append(lst[3])\n",
    "        model_out['prob_negative'].append(lst[5])\n",
    "        model_out['prob_positive'].append(lst[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame.from_dict(model_out)\n",
    "df2 = DataFrame.from_records(test_data)\n",
    "\n",
    "table = concat([df2['response'], df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly check stats\n",
    "print(table.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 20 of the incorrectly classified examples\n",
    "print(table.loc[table['pred'] != table['gold']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore false positives (model label = sarcastic, gold label = not sarcastic)\n",
    "false_pos = table.loc[(table['pred'] == '1') & (table['gold'] == '0')]\n",
    "print(false_pos.head(20))\n",
    "print('count false positives:', false_pos.shape[0])\n",
    "print('count true positives:', table.loc[(table['pred'] == '1') & (table['gold'] == '1')].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore false negatives (model label = not sarcastic, gold label = sarcastic)\n",
    "false_neg = table.loc[(table['pred'] == '0') & (table['gold'] == '1')]\n",
    "print(false_neg.head(20))\n",
    "print('count false negatives:', false_neg.shape[0])\n",
    "print('count true negatives:', table.loc[(table['pred'] == '0') & (table['gold'] == '0')].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = metrics.confusion_matrix(model_out['gold'], model_out['pred'])\n",
    "cm_graphic = metrics.ConfusionMatrixDisplay(con_mat, display_labels=['Not Sarcastic', 'Sarcastic'])\n",
    "cm_graphic.plot()\n",
    "plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
